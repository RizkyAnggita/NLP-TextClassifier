{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /Users/macbook/opt/anaconda3/lib/python3.9/site-packages (4.1.2)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /Users/macbook/opt/anaconda3/lib/python3.9/site-packages (from gensim) (1.22.4)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/macbook/opt/anaconda3/lib/python3.9/site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /Users/macbook/opt/anaconda3/lib/python3.9/site-packages (from gensim) (1.7.3)\n"
     ]
    }
   ],
   "source": [
    "! pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"./data_worthcheck/train.csv\")\n",
    "test_data = pd.read_csv(\"./data_worthcheck/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"label\"] = train_data[\"label\"].map({'no': 0, 'yes':1})\n",
    "test_data[\"label\"] = test_data[\"label\"].map({'no': 0, 'yes':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATA\n",
      "NO:  15512\n",
      "YES:  6089\n",
      "NO + YES =  21601\n",
      "TOTAL:  21601\n"
     ]
    }
   ],
   "source": [
    "print(\"TRAIN DATA\")\n",
    "len_train_0 = len(train_data[train_data[\"label\"] == 0])\n",
    "len_train_1 = len(train_data[train_data[\"label\"] == 1])\n",
    "len_train = len(train_data)\n",
    "print(\"NO: \", len_train_0)\n",
    "print(\"YES: \", len_train_1)\n",
    "print(\"NO + YES = \", len_train_0 + len_train_1)\n",
    "print(\"TOTAL: \", len_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST DATA\n",
      "NO:  2093\n",
      "YES:  707\n",
      "NO + YES =  2800\n",
      "TOTAL:  2800\n"
     ]
    }
   ],
   "source": [
    "print(\"TEST DATA\")\n",
    "len_test_0 = len(test_data[test_data[\"label\"] == 0])\n",
    "len_test_1 = len(test_data[test_data[\"label\"] == 1])\n",
    "len_test = len(test_data)\n",
    "print(\"NO: \", len_test_0)\n",
    "print(\"YES: \", len_test_1)\n",
    "print(\"NO + YES = \", len_test_0 + len_test_1)\n",
    "print(\"TOTAL: \", len_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_a</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jek dajal ga depok bang</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>detikcom untung depok masuk wilayah nya ridwan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>df dom jakarta depok yg gunain vc cabang nya c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>your2rl depok jkt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doakan indonesia selamat virus corona pkb depo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_a  label\n",
       "0                            jek dajal ga depok bang      0\n",
       "1  detikcom untung depok masuk wilayah nya ridwan...      0\n",
       "2  df dom jakarta depok yg gunain vc cabang nya c...      0\n",
       "3                                  your2rl depok jkt      0\n",
       "4  doakan indonesia selamat virus corona pkb depo...      1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_a</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>betewe buka twitter cuman ngetweet liat home b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mas piyuuu mugo2 corona tuh mulut tersumpal ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e100ss gini buka informasi sejelas nya identit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neng solo wes ono terduga corona cobo neng ati...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>midiahn nii akun gak takut takut nya isu coron...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_a  label\n",
       "0  betewe buka twitter cuman ngetweet liat home b...      0\n",
       "1  mas piyuuu mugo2 corona tuh mulut tersumpal ma...      0\n",
       "2  e100ss gini buka informasi sejelas nya identit...      1\n",
       "3  neng solo wes ono terduga corona cobo neng ati...      0\n",
       "4  midiahn nii akun gak takut takut nya isu coron...      0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53d298ca40404435a2e07e527d02696a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21601 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4682cdb20a764334a09a9d397b4b036e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_sentences = [word_tokenize(text.lower()) for text in tqdm(train_data.text_a)]\n",
    "test_sentences = [word_tokenize(text.lower()) for text in tqdm(test_data.text_a)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. CASE FOLDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77f82a8c817d403f92311dbd5632aaf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21601 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e237673456174de2a54318fffd38db5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CASE FOLDING\n",
    "\n",
    "for idx,sentence in enumerate(tqdm(train_data[\"text_a\"])):\n",
    "    train_data.at[idx,'text_a'] = sentence.lower()\n",
    "\n",
    "for idx,sentence in enumerate(tqdm(test_data[\"text_a\"])):\n",
    "    test_data.at[idx,\"text_a\"] = sentence.lower()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. STEMMING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Sastrawi in /Users/macbook/opt/anaconda3/lib/python3.9/site-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install Sastrawi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec5632c4f4d3482ca15819e8f62173cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21601 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7976817156de4b58988273ba4d310d7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# STEMMING\n",
    "\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "for idx,sentence in enumerate(tqdm(train_data[\"text_a\"])):\n",
    "    train_data.at[idx,'text_a'] = stemmer.stem(sentence)\n",
    "\n",
    "for idx,sentence in enumerate(tqdm(test_data[\"text_a\"])):\n",
    "    test_data.at[idx,\"text_a\"] = stemmer.stem(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. STOP WORD REMOVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c22d3335882449e0b3391e58f58443b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21601 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1482d21f4cc541b9a5bd4ecd714fbec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# STOP WORD REMOVAL\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "indonesian_stopwords = stopwords.words('indonesian')\n",
    "\n",
    "train_stop_removed = []\n",
    "test_stop_removed = []\n",
    "\n",
    "for sentence in tqdm(train_data[\"text_a\"]):\n",
    "    sentence_stop_removed = [word for word in sentence.split(\" \") if word not in indonesian_stopwords]\n",
    "    sentence_stop_removed = \" \".join(sentence_stop_removed)\n",
    "    train_stop_removed.append(sentence_stop_removed)\n",
    "\n",
    "for sentence in tqdm(test_data[\"text_a\"]):\n",
    "    sentence_stop_removed = [word for word in sentence.split(\" \") if word not in indonesian_stopwords]\n",
    "    sentence_stop_removed = \" \".join(sentence_stop_removed)\n",
    "    test_stop_removed.append(sentence_stop_removed)\n",
    "\n",
    "train_data[\"text_a\"] = train_stop_removed\n",
    "test_data[\"text_a\"] = test_stop_removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train FastText Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data preparation for fasttext\n",
    "\n",
    "# create fasttext readable train data\n",
    "with open('fasttext_train.txt', 'w+') as f:\n",
    "    for each_text, each_label in zip(train_data['text_a'], train_data['label']):\n",
    "        f.writelines(f'__label__{each_label} {each_text}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create fasttext readable test data\n",
    "with open('fasttext_test.txt', 'w') as f:\n",
    "    for each_text, each_label in zip(test_data['text_a'], test_data['label']):\n",
    "        f.writelines(f'__label__{each_label} {each_text}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__label__0 betewe buka twitter cuman ngetweet liat home berita corona panik pikir ndamau buka2 home yg aware aja i ll stay at home nda rumah kalo nda penting2 banget\n",
      "__label__0 mas piyuuu mugo2 corona tuh mulut sumpal ma corona\n",
      "__label__1 e100ss gin buka informasi nya identitas daerah derita jangkit info masyarakat isolasi nya kontak langsung derita positif corona tutup tutup\n",
      "__label__0 neng solo wes ono duga corona cobo neng ati mu neng conora\n",
      "__label__0 midiahn nii akun gak takut takut nya isu corona wkwkwkw\n",
      "__label__0 hey corona prrgi sna\n",
      "__label__0 gara corona masuk aja mesti scan jidat gw kek jajan indomaret\n",
      "__label__1 jokowi menteri2 nya sila tes corona\n",
      "__label__1 cegah corona other moms minum multivitamin my mom minum rebus sambiloto\n",
      "__label__0 mamaciaaa mnrut gue jngan dkt2 corona cb dkt yg y puspa jaya damri als dkt tran jakarta aj\n"
     ]
    }
   ],
   "source": [
    "! head -n 10 fasttext_train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__label__0 jek dajal ga depok bang\n",
      "__label__0 detikcom untung depok masuk wilayah nya ridwan kamil kalo masuk wilayah nya anis abis lu bully ama buzzer kolam\n",
      "__label__0 df dom jakarta depok yg gunain vc cabang nya cabang yg cantum pas kesana gabisa bayar pake shopeepay\n",
      "__label__0 your2rl depok jkt\n",
      "__label__1 doa indonesia selamat virus corona pkb depok gelar nusantara bershalawat\n",
      "__label__1 warga depok ganggu isu corona\n",
      "__label__1 kenapaa dengar kabar salah wni positif corona depok tinggal ku ku kawatir takut\n",
      "__label__0 hug f cibinong bogor depok ga makan siang bareng m24\n",
      "__label__0 mukenahhh tlongggg ak maw hp ak kentank bingits sdh belah hadiah ultah hshs ak depok btw follback yh\n",
      "__label__0 g00d p4r3nts gilir corvid 19 jakarta beda depok banjir jakarta\n"
     ]
    }
   ],
   "source": [
    "! head -n 10 fasttext_test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS\n",
    "vector_size = 128\n",
    "window = 5\n",
    "min_count = 3\n",
    "workers = 4\n",
    "iter = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  11862\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread: 1415012 lr:  0.000000 avg.loss:  0.048748 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "file_to_train = 'fasttext_train.txt'\n",
    "\n",
    "model = fasttext.train_supervised(\n",
    "    file_to_train,\n",
    "    dim = vector_size,\n",
    "    epoch = iter,\n",
    "    minCount = 3,\n",
    "    verbose= True,\n",
    "    ws = window\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('model/fasttext/', exist_ok=True)\n",
    "model.save_model('model/fasttext/trained.fasttext')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berikut ini nilai precision, recall, da f1 score dari hasil testing file test\n",
      "Number of test data : 2800\n",
      "Precision : 0.7857142857142857\n",
      "Recall : 0.7857142857142857\n"
     ]
    }
   ],
   "source": [
    "file_to_test = 'fasttext_test.txt'\n",
    "\n",
    "print('Berikut ini nilai precision, recall, da f1 score dari hasil testing file test')\n",
    "\n",
    "result = model.test(\n",
    "    file_to_test)\n",
    "\n",
    "num_data = result[0]\n",
    "precision = result[1]\n",
    "recall = result[2]\n",
    "\n",
    "print(\"Number of test data :\", num_data)\n",
    "print(\"Precision :\", precision)\n",
    "print(\"Recall :\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__0',), array([1.00001001]))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manual testing\n",
    "\n",
    "print('Berikut ini nilai precision, recall, dan f1 score dari pengujian testing file secara manual.')\n",
    "\n",
    "precision = 0\n",
    "recall = 0\n",
    "\n",
    "model.\n",
    "\n",
    "for idx,sentence in enumerate(tqdm(test_data[\"text_a\"])):\n",
    "    m\n",
    "\n",
    "for idx,sentence in enumerate(tqdm(test_data[\"text_a\"])):\n",
    "    test_data.at[idx,\"text_a\"] = sentence.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88de8a03d390c9821a705f8812eeaeda47efe29e530260f109fd5a47346b85c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
